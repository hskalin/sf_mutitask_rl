name: "sfgpi"
is_clip_max: 1.0
entropy_tuning: True
alpha: 1.
alpha_lr: 3e-4
lr: 0.002236613447518631 
policy_lr: 0.006458911999719074 
gamma: 0.99
tau: 5e-3
td_target_update_interval: 1
updates_per_step: 1
reward_scale: 1.0
grad_clip: null
value_net_kwargs: 
    sizes: [256, 256]
    activation: "relu"
    layernorm: True
    droprate: 0.0
policy_net_kwargs: 
    sizes: [128, 128]
    layernorm: False

augmentHeads: True