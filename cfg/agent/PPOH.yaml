name: "ppoh"
total_timesteps: 30000000
batch_size: 2048
learning_rate: 0.0026
minibatch_size: 1024
num_steps: 16
anneal_lr: True
gamma: 0.99
gae_lambda: 0.95
num_minibatches: 2
update_epochs: 4
norm_adv: True
clip_coef: 0.2
clip_vloss: False
ent_coef: 0.0
vf_coef: 2
max_grad_norm: 1
target_kl: null

SFGPI:
  name: "sfgpi"
  is_clip_max: 1.0
  entropy_tuning: True
  alpha: 1.
  alpha_lr: 3e-4
  lr: 0.002236613447518631 
  policy_lr: 0.006458911999719074 
  gamma: 0.99
  tau: 5e-3
  td_target_update_interval: 1
  updates_per_step: 1
  reward_scale: 1.0
  grad_clip: null
  value_net_kwargs: 
      sizes: [256, 256]
      activation: "relu"
      layernorm: True
      droprate: 0.0
  policy_net_kwargs: 
      sizes: [128, 128]
      layernorm: False